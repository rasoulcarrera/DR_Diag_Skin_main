{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers accelerate peft tqdm pillow datasets wandb pandas bitsandbytes --q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded ✓\n"
     ]
    }
   ],
   "source": [
    "# Skin Disease Diagnosis Training with Hugging Face Dataset\n",
    "import torch\n",
    "import random\n",
    "from PIL import Image\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    Qwen2VLForConditionalGeneration,\n",
    "    Qwen2VLProcessor,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "print(\"Libraries loaded ✓\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config loaded - Dataset: abaryan/ham10000_bbox\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    \"model_name\": \"Qwen/Qwen2-VL-2B-Instruct\",\n",
    "    \"hf_dataset_name\": \"abaryan/ham10000_bbox\",\n",
    "    \"output_dir\": \"./qwen2vl-skin-diagnosis-hf\",\n",
    "    \"num_train_epochs\": 3,\n",
    "    \"per_device_train_batch_size\": 10,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"learning_rate\": 5e-5,\n",
    "    \"warmup_steps\": 100,\n",
    "    \"max_length\": 512,\n",
    "    \"include_spatial_descriptions\": True,\n",
    "    \"spatial_description_ratio\": 0.3,\n",
    "    \"train_limit\": None,\n",
    "    \"test_limit\": None\n",
    "}\n",
    "\n",
    "print(f\"Config loaded - Dataset: {CONFIG['hf_dataset_name']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b259c714da824e4795bf6dd0d76abfa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "556470503a71406683a7c35d032b0917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdd7e5a7f2964b58bed109454cef6baf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "291a2043c71c402b8ee38c2d892144df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/429M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab9d96821f148dcb394a3ac618a3604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/3.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1057676d03e4568be9c902253581a8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbdd038fb8ed4e4eac0e697f52d2a905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/272 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f206f462da5d4bc48e49e8fa0254b25d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "901d1ea0f3f547629c96b0813f7ebe30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/347 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "870e9f3cde844974b87b444bb5d8353d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f111755e01a946878376aa608e59d893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c58bae81b65245bcaf8200042778d6fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecdea89c55314301b925a2a819f98129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d52390e6f8c34192ae130d5bf8e2956e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb1846883be41bba30f62847032b4b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded ✓\n"
     ]
    }
   ],
   "source": [
    "# Load model and processor\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    CONFIG[\"model_name\"],\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "processor = Qwen2VLProcessor.from_pretrained(CONFIG[\"model_name\"])\n",
    "\n",
    "print(\"Model loaded ✓\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd15986732040358d2d1d5aa60e3938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/814 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "496fb39cafa24f91b7f7539f7cedd0ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00008.parquet:   0%|          | 0.00/375M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81ebb8faee354aa88a517cf180e067e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00001-of-00008.parquet:   0%|          | 0.00/374M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aaf7dbe8fd14471bea6883f0acee88c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00002-of-00008.parquet:   0%|          | 0.00/375M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba267d184fe5432ca07c8ebf174f0120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00003-of-00008.parquet:   0%|          | 0.00/377M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e6b8722234d4d908109f13a66ed9b4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00004-of-00008.parquet:   0%|          | 0.00/376M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea6f5331dd8a4edcbf3981d7cf31a338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00005-of-00008.parquet:   0%|          | 0.00/378M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ce1e60d3f84c559195a995dea475ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00006-of-00008.parquet:   0%|          | 0.00/375M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1bcdcae7e9442f7a6dd5c5e9c54a67c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00007-of-00008.parquet:   0%|          | 0.00/376M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ad15f48607040899b7196601bb9bfc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00002.parquet:   0%|          | 0.00/374M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4f3d61da95435e9c35efe540a43ee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00001-of-00002.parquet:   0%|          | 0.00/375M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a28530b7ed90434083501704f018f8d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/8012 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "411173154266418d9add0503ff96e609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/2003 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8012 train samples, 2003 test samples\n",
      "Prepared 8012 train conversations\n",
      "Prepared 2003 test conversations\n"
     ]
    }
   ],
   "source": [
    "# Load Hugging Face dataset\n",
    "def load_hf_dataset():\n",
    "    \"\"\"Load and prepare HF dataset for training\"\"\"\n",
    "    \n",
    "    # Load dataset\n",
    "    hf_dataset = load_dataset(CONFIG[\"hf_dataset_name\"])\n",
    "    \n",
    "    # Get train/test splits\n",
    "    train_data = hf_dataset['train']\n",
    "    test_data = hf_dataset['test']\n",
    "    \n",
    "    if CONFIG[\"train_limit\"]:\n",
    "        train_data = train_data.select(range(min(CONFIG[\"train_limit\"], len(train_data))))\n",
    "    if CONFIG[\"test_limit\"]:\n",
    "        test_data = test_data.select(range(min(CONFIG[\"test_limit\"], len(test_data))))\n",
    "    \n",
    "    print(f\"Loaded {len(train_data)} train samples, {len(test_data)} test samples\")\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "def prepare_conversations(dataset_split):\n",
    "    \"\"\"Convert HF dataset to conversation format - Memory Efficient\"\"\"\n",
    "    \n",
    "    conversations = []\n",
    "    \n",
    "    # Diagnosis mapping\n",
    "    dx_names = {\n",
    "        'akiec': 'actinic keratosis',\n",
    "        'bcc': 'basal cell carcinoma', \n",
    "        'bkl': 'benign keratosis-like lesion',\n",
    "        'df': 'dermatofibroma',\n",
    "        'mel': 'melanoma',\n",
    "        'nv': 'melanocytic nevus',\n",
    "        'vasc': 'vascular lesion'\n",
    "    }\n",
    "    \n",
    "    for i, item in enumerate(dataset_split):\n",
    "        dx = item['diagnosis']\n",
    "        diagnosis_full = dx_names.get(dx, dx)\n",
    "        \n",
    "        # Spatial awareness logic\n",
    "        use_spatial = (CONFIG[\"include_spatial_descriptions\"] and \n",
    "                      item.get('mask_available', False) and \n",
    "                      random.random() < CONFIG[\"spatial_description_ratio\"])\n",
    "        \n",
    "        if use_spatial and item.get('spatial_description'):\n",
    "            user_prompt = \"Analyze this skin lesion, provide a diagnosis, and describe its location.\"\n",
    "            spatial_desc = item['spatial_description'].replace('lesion located in', 'The lesion is located in the')\n",
    "            assistant_response = f\"This appears to be {diagnosis_full}. {spatial_desc}.\"\n",
    "        else:\n",
    "            user_prompt = \"Analyze this skin lesion and provide a diagnosis.\"\n",
    "            assistant_response = f\"This appears to be {diagnosis_full}.\"\n",
    "        \n",
    "        conversation = {\n",
    "            \"conversation\": [\n",
    "                {\"role\": \"user\", \"content\": [{\"type\": \"image\"}, {\"type\": \"text\", \"text\": user_prompt}]},\n",
    "                {\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": assistant_response}]}\n",
    "            ],\n",
    "            \"hf_index\": i,  # Store index instead of image\n",
    "            \"metadata\": {\n",
    "                \"lesion_id\": item.get('lesion_id'),\n",
    "                \"diagnosis\": dx,\n",
    "                \"has_spatial\": use_spatial,\n",
    "                \"bbox\": item.get('bbox'),\n",
    "                \"area_coverage\": item.get('area_coverage'),\n",
    "                \"mask_available\": item.get('mask_available', False)\n",
    "            }\n",
    "        }\n",
    "        conversations.append(conversation)\n",
    "    \n",
    "    return conversations, dataset_split  # Return dataset_split for image access\n",
    "\n",
    "# Load data\n",
    "train_hf, test_hf = load_hf_dataset()\n",
    "train_conversations, train_hf_data = prepare_conversations(train_hf)\n",
    "test_conversations, test_hf_data = prepare_conversations(test_hf)\n",
    "\n",
    "print(f\"Prepared {len(train_conversations)} train conversations\")\n",
    "print(f\"Prepared {len(test_conversations)} test conversations\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collate function ready ✓\n"
     ]
    }
   ],
   "source": [
    "# Memory-efficient data collator for HF dataset\n",
    "def collate_fn(examples):\n",
    "    texts = []\n",
    "    images = []\n",
    "    \n",
    "    for example in examples:\n",
    "        # Load image on-demand from HF dataset using index\n",
    "        hf_index = example[\"hf_index\"]\n",
    "        image = train_hf_data[hf_index]['image'].convert('RGB')\n",
    "        images.append(image)\n",
    "        \n",
    "        text = processor.apply_chat_template(\n",
    "            example[\"conversation\"], \n",
    "            tokenize=False, \n",
    "            add_generation_prompt=False\n",
    "        )\n",
    "        texts.append(text)\n",
    "    \n",
    "    batch = processor(\n",
    "        text=texts,\n",
    "        images=images, \n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=CONFIG[\"max_length\"]\n",
    "    )\n",
    "    \n",
    "    labels = batch[\"input_ids\"].clone()\n",
    "    labels[labels == processor.tokenizer.pad_token_id] = -100\n",
    "    \n",
    "    if hasattr(processor, 'image_token_id'):\n",
    "        labels[labels == processor.image_token_id] = -100\n",
    "    \n",
    "    batch[\"labels\"] = labels\n",
    "    return batch\n",
    "\n",
    "print(\"Collate function ready ✓\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 73,859,072 || all params: 2,282,844,672 || trainable%: 3.2354\n",
      "LoRA setup complete ✓\n"
     ]
    }
   ],
   "source": [
    "# Setup LoRA\n",
    "lora_config = LoraConfig(\n",
    "    r=64,\n",
    "    lora_alpha=128,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "print(\"LoRA setup complete ✓\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrasoulcarrera\u001b[0m (\u001b[33mrasoulcarrera-aba\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import wandb\n",
    "# wandb.login(key=\"f1aedbcd5d073259cb4005220e80f8f3bab2dd69\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer ready ✓\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2354/4098435719.py:21: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# Training setup\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=CONFIG[\"output_dir\"],\n",
    "    num_train_epochs=CONFIG[\"num_train_epochs\"],\n",
    "    per_device_train_batch_size=CONFIG[\"per_device_train_batch_size\"],\n",
    "    gradient_accumulation_steps=CONFIG[\"gradient_accumulation_steps\"],\n",
    "    learning_rate=CONFIG[\"learning_rate\"],\n",
    "    warmup_steps=CONFIG[\"warmup_steps\"],\n",
    "     # Logging and saving\n",
    "    logging_steps=50,\n",
    "    save_steps=1000,\n",
    "    eval_steps=300,\n",
    "    save_total_limit=1,\n",
    "    \n",
    "    remove_unused_columns=False,\n",
    "    push_to_hub=False,\n",
    "    report_to='wandb',\n",
    "    dataloader_pin_memory=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_conversations,\n",
    "    data_collator=collate_fn,\n",
    "    tokenizer=processor.tokenizer\n",
    ")\n",
    "\n",
    "print(\"Trainer ready ✓\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.2s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250904_115050-uvz38dx0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rasoulcarrera-aba/huggingface/runs/uvz38dx0' target=\"_blank\">likely-forest-353</a></strong> to <a href='https://wandb.ai/rasoulcarrera-aba/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rasoulcarrera-aba/huggingface' target=\"_blank\">https://wandb.ai/rasoulcarrera-aba/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rasoulcarrera-aba/huggingface/runs/uvz38dx0' target=\"_blank\">https://wandb.ai/rasoulcarrera-aba/huggingface/runs/uvz38dx0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2406' max='2406' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2406/2406 38:17, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.160500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.428100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.362900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.360300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.357700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.360200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.354900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.353400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.356800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.358300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.359000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.354400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.356500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.349900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.354200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.355200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.349800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.353900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.352000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.350300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.352800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.350800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.355000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.350900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.353000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.349300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.349900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.349500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.350300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.349500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.354600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.352600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.347800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.347600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.342800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.346900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.348300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.346600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.345400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.344600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.347300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.343500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.345900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.348600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.347600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.346600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.345200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.346800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete!\n",
      "Model saved ✓\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "print(\"Starting training...\")\n",
    "trainer.train()\n",
    "print(\"Training complete!\")\n",
    "\n",
    "# Save model and processor\n",
    "trainer.save_model(CONFIG[\"output_dir\"])\n",
    "processor.save_pretrained(CONFIG[\"output_dir\"])\n",
    "print(\"Model saved ✓\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e41cf2df1fc4ab4b666e63f768fbeef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f28d7545ac33480585fcf5db918a6ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model...\n",
      "\n",
      "--- Test 1/50 ---\n",
      "Image: HF_sample_1\n",
      "Ground Truth: This appears to be melanocytic nevus.\n",
      "Model Output: This appears to be melanocytic nevus.\n",
      "Diagnosis: ✓ | Spatial: ✓\n",
      "Overall: ✓ CORRECT\n",
      "\n",
      "--- Test 2/50 ---\n",
      "Image: HF_sample_2\n",
      "Ground Truth: This appears to be melanoma.\n",
      "Model Output: This appears to be melanoma.\n",
      "Diagnosis: ✓ | Spatial: ✓\n",
      "Overall: ✓ CORRECT\n",
      "\n",
      "--- Test 3/50 ---\n",
      "Image: HF_sample_3\n",
      "Ground Truth: This appears to be melanocytic nevus.\n",
      "Model Output: This appears to be melanocytic nevus.\n",
      "Diagnosis: ✓ | Spatial: ✓\n",
      "Overall: ✓ CORRECT\n",
      "\n",
      "--- Test 4/50 ---\n",
      "Image: HF_sample_4\n",
      "Ground Truth: This appears to be melanocytic nevus.\n",
      "Model Output: This appears to be melanocytic nevus.\n",
      "Diagnosis: ✓ | Spatial: ✓\n",
      "Overall: ✓ CORRECT\n",
      "\n",
      "--- Test 5/50 ---\n",
      "Image: HF_sample_5\n",
      "Ground Truth: This appears to be melanocytic nevus.\n",
      "Model Output: This appears to be melanocytic nevus.\n",
      "Diagnosis: ✓ | Spatial: ✓\n",
      "Overall: ✓ CORRECT\n",
      "\n",
      "--- Test 6/50 ---\n",
      "Image: HF_sample_6\n",
      "Ground Truth: This appears to be actinic keratosis.\n",
      "Model Output: This appears to be actinic keratosis.\n",
      "Diagnosis: ✓ | Spatial: ✓\n",
      "Overall: ✓ CORRECT\n",
      "\n",
      "--- Test 7/50 ---\n",
      "Image: HF_sample_7\n",
      "Ground Truth: This appears to be melanoma.\n",
      "Model Output: This appears to be melanocytic nevus.\n",
      "Diagnosis: ❌ | Spatial: ✓\n",
      "Overall: ❌ INCORRECT\n",
      "\n",
      "--- Test 8/50 ---\n",
      "Image: HF_sample_8\n",
      "Ground Truth: This appears to be melanocytic nevus.\n",
      "Model Output: This appears to be melanocytic nevus.\n",
      "Diagnosis: ✓ | Spatial: ✓\n",
      "Overall: ✓ CORRECT\n",
      "\n",
      "--- Test 9/50 ---\n",
      "Image: HF_sample_9\n",
      "Ground Truth: This appears to be melanoma. The lesion is located in the center-center region.\n",
      "Model Output: This appears to be melanocytic nevus. The lesion is located in the center-center region.\n",
      "Diagnosis: ❌ | Spatial: ✓\n",
      "Overall: ❌ INCORRECT\n",
      "Spatial GT: 'the center-center region' | Pred: 'the center-center region'\n",
      "Bbox: [84, 28, 515, 394]\n",
      "Area Coverage: 43.4%\n",
      "\n",
      "--- Test 10/50 ---\n",
      "Image: HF_sample_10\n",
      "Ground Truth: This appears to be melanocytic nevus.\n",
      "Model Output: This appears to be melanocytic nevus.\n",
      "Diagnosis: ✓ | Spatial: ✓\n",
      "Overall: ✓ CORRECT\n",
      "\n",
      "--- Test 11/50 ---\n",
      "Image: HF_sample_11\n",
      "Ground Truth: This appears to be melanocytic nevus.\n",
      "Model Output: This appears to be melanocytic nevus.\n",
      "Diagnosis: ✓ | Spatial: ✓\n",
      "Overall: ✓ CORRECT\n",
      "\n",
      "--- Test 12/50 ---\n",
      "Image: HF_sample_12\n",
      "Ground Truth: This appears to be melanocytic nevus.\n",
      "Model Output: This appears to be melanocytic nevus.\n",
      "Diagnosis: ✓ | Spatial: ✓\n",
      "Overall: ✓ CORRECT\n",
      "\n",
      "--- Test 13/50 ---\n",
      "Image: HF_sample_13\n",
      "Ground Truth: This appears to be melanocytic nevus. The lesion is located in the center-center region.\n",
      "Model Output: This appears to be melanocytic nevus. The lesion is located in the center-center region.\n",
      "Diagnosis: ✓ | Spatial: ✓\n",
      "Overall: ✓ CORRECT\n",
      "Spatial GT: 'the center-center region' | Pred: 'the center-center region'\n",
      "Bbox: [99, 0, 544, 450]\n",
      "Area Coverage: 60.1%\n",
      "\n",
      "--- Test 14/50 ---\n",
      "Image: HF_sample_14\n",
      "Ground Truth: This appears to be benign keratosis-like lesion.\n",
      "Model Output: This appears to be benign keratosis-like lesion.\n",
      "Diagnosis: ✓ | Spatial: ✓\n",
      "Overall: ✓ CORRECT\n",
      "\n",
      "--- Test 15/50 ---\n",
      "Image: HF_sample_15\n",
      "Ground Truth: This appears to be melanocytic nevus. The lesion is located in the center-center region.\n",
      "Model Output: This appears to be melanocytic nevus. The lesion is located in the center-center region.\n",
      "Diagnosis: ✓ | Spatial: ✓\n",
      "Overall: ✓ CORRECT\n",
      "Spatial GT: 'the center-center region' | Pred: 'the center-center region'\n",
      "Bbox: [270, 146, 354, 299]\n",
      "Area Coverage: 3.7%\n",
      "\n",
      "--- Test 16/50 ---\n",
      "Image: HF_sample_16\n",
      "Ground Truth: This appears to be melanoma.\n",
      "Model Output: This appears to be melanoma.\n",
      "Diagnosis: ✓ | Spatial: ✓\n",
      "Overall: ✓ CORRECT\n",
      "\n",
      "--- Test 17/50 ---\n",
      "Image: HF_sample_17\n",
      "Ground Truth: This appears to be melanocytic nevus.\n",
      "Model Output: This appears to be melanocytic nevus.\n",
      "Diagnosis: ✓ | Spatial: ✓\n",
      "Overall: ✓ CORRECT\n",
      "\n",
      "--- Test 18/50 ---\n",
      "Image: HF_sample_18\n",
      "Ground Truth: This appears to be melanocytic nevus.\n",
      "Model Output: This appears to be melanocytic nevus.\n",
      "Diagnosis: ✓ | Spatial: ✓\n",
      "Overall: ✓ CORRECT\n",
      "\n",
      "--- Test 19/50 ---\n",
      "Image: HF_sample_19\n",
      "Ground Truth: This appears to be melanocytic nevus.\n",
      "Model Output: This appears to be melanocytic nevus.\n",
      "Diagnosis: ✓ | Spatial: ✓\n",
      "Overall: ✓ CORRECT\n",
      "\n",
      "--- Test 20/50 ---\n",
      "Image: HF_sample_20\n",
      "Ground Truth: This appears to be melanocytic nevus. The lesion is located in the center-center region.\n",
      "Model Output: This appears to be melanocytic nevus. The lesion is located in the center-center region.\n",
      "Diagnosis: ✓ | Spatial: ✓\n",
      "Overall: ✓ CORRECT\n",
      "Spatial GT: 'the center-center region' | Pred: 'the center-center region'\n",
      "Bbox: [150, 168, 399, 340]\n",
      "Area Coverage: 11.5%\n",
      "\n",
      "--- Test 21/50 ---\n",
      "Image: HF_sample_21\n",
      "Ground Truth: This appears to be melanocytic nevus.\n",
      "Model Output: This appears to be melanocytic nevus.\n",
      "Diagnosis: ✓ | Spatial: ✓\n",
      "Overall: ✓ CORRECT\n",
      "\n",
      "--- Test 22/50 ---\n",
      "Image: HF_sample_22\n",
      "Ground Truth: This appears to be actinic keratosis. The lesion is located in the center-center region.\n",
      "Model Output: This appears to be actinic keratosis. The lesion is located in the center-center region.\n",
      "Diagnosis: ✓ | Spatial: ✓\n",
      "Overall: ✓ CORRECT\n",
      "Spatial GT: 'the center-center region' | Pred: 'the center-center region'\n",
      "Bbox: [152, 0, 600, 442]\n",
      "Area Coverage: 45.5%\n",
      "\n",
      "--- Test 23/50 ---\n",
      "Image: HF_sample_23\n",
      "Ground Truth: This appears to be melanocytic nevus. The lesion is located in the center-center region.\n",
      "Model Output: This appears to be melanocytic nevus. The lesion is located in the center-center region.\n",
      "Diagnosis: ✓ | Spatial: ✓\n",
      "Overall: ✓ CORRECT\n",
      "Spatial GT: 'the center-center region' | Pred: 'the center-center region'\n",
      "Bbox: [261, 191, 385, 315]\n",
      "Area Coverage: 3.7%\n",
      "\n",
      "--- Test 24/50 ---\n",
      "Image: HF_sample_24\n",
      "Ground Truth: This appears to be melanocytic nevus.\n",
      "Model Output: This appears to be melanocytic nevus.\n",
      "Diagnosis: ✓ | Spatial: ✓\n",
      "Overall: ✓ CORRECT\n",
      "\n",
      "--- Test 25/50 ---\n",
      "Image: HF_sample_25\n",
      "Ground Truth: This appears to be melanocytic nevus.\n",
      "Model Output: This appears to be melanocytic nevus.\n",
      "Diagnosis: ✓ | Spatial: ✓\n",
      "Overall: ✓ CORRECT\n",
      "\n",
      "--- Test 26/50 ---\n",
      "Image: HF_sample_26\n",
      "Ground Truth: This appears to be melanocytic nevus.\n",
      "Model Output: This appears to be melanocytic nevus.\n",
      "Diagnosis: ✓ | Spatial: ✓\n",
      "Overall: ✓ CORRECT\n",
      "\n",
      "--- Test 27/50 ---\n",
      "Image: HF_sample_27\n",
      "Ground Truth: This appears to be melanoma.\n",
      "Model Output: This appears to be melanocytic nevus.\n",
      "Diagnosis: ❌ | Spatial: ✓\n",
      "Overall: ❌ INCORRECT\n",
      "\n",
      "--- Test 28/50 ---\n",
      "Image: HF_sample_28\n",
      "Ground Truth: This appears to be actinic keratosis. The lesion is located in the center-center region.\n",
      "Model Output: This appears to be melanocytic nevus. The lesion is located in the center-center region.\n",
      "Diagnosis: ❌ | Spatial: ✓\n",
      "Overall: ❌ INCORRECT\n",
      "Spatial GT: 'the center-center region' | Pred: 'the center-center region'\n",
      "Bbox: [181, 71, 501, 374]\n",
      "Area Coverage: 22.0%\n",
      "\n",
      "--- Test 29/50 ---\n",
      "Image: HF_sample_29\n",
      "Ground Truth: This appears to be benign keratosis-like lesion.\n",
      "Model Output: This appears to be benign keratosis-like lesion.\n",
      "Diagnosis: ✓ | Spatial: ✓\n",
      "Overall: ✓ CORRECT\n",
      "\n",
      "--- Test 30/50 ---\n",
      "Image: HF_sample_30\n",
      "Ground Truth: This appears to be melanocytic nevus.\n",
      "Model Output: This appears to be benign keratosis-like lesion.\n",
      "Diagnosis: ❌ | Spatial: ✓\n",
      "Overall: ❌ INCORRECT\n",
      "\n",
      "--- Test 31/50 ---\n",
      "Image: HF_sample_31\n",
      "Ground Truth: This appears to be basal cell carcinoma.\n",
      "Model Output: This appears to be basal cell carcinoma.\n",
      "Diagnosis: ✓ | Spatial: ✓\n",
      "Overall: ✓ CORRECT\n",
      "\n",
      "--- Test 32/50 ---\n",
      "Image: HF_sample_32\n",
      "Ground Truth: This appears to be melanocytic nevus.\n",
      "Model Output: This appears to be melanocytic nevus.\n",
      "Diagnosis: ✓ | Spatial: ✓\n",
      "Overall: ✓ CORRECT\n",
      "\n",
      "--- Test 33/50 ---\n",
      "Image: HF_sample_33\n",
      "Ground Truth: This appears to be benign keratosis-like lesion.\n",
      "Model Output: This appears to be benign keratosis-like lesion.\n",
      "Diagnosis: ✓ | Spatial: ✓\n",
      "Overall: ✓ CORRECT\n",
      "\n",
      "--- Test 34/50 ---\n",
      "Image: HF_sample_34\n",
      "Ground Truth: This appears to be benign keratosis-like lesion.\n",
      "Model Output: This appears to be benign keratosis-like lesion.\n",
      "Diagnosis: ✓ | Spatial: ✓\n",
      "Overall: ✓ CORRECT\n",
      "\n",
      "--- Test 35/50 ---\n",
      "Image: HF_sample_35\n",
      "Ground Truth: This appears to be melanocytic nevus.\n",
      "Model Output: This appears to be melanocytic nevus.\n",
      "Diagnosis: ✓ | Spatial: ✓\n",
      "Overall: ✓ CORRECT\n",
      "\n",
      "--- Test 36/50 ---\n",
      "Image: HF_sample_36\n",
      "Ground Truth: This appears to be melanocytic nevus.\n",
      "Model Output: This appears to be melanocytic nevus.\n",
      "Diagnosis: ✓ | Spatial: ✓\n",
      "Overall: ✓ CORRECT\n",
      "\n",
      "--- Test 37/50 ---\n",
      "Image: HF_sample_37\n",
      "Ground Truth: This appears to be melanocytic nevus. The lesion is located in the center-center region.\n",
      "Model Output: This appears to be melanocytic nevus. The lesion is located in the center-center region.\n",
      "Diagnosis: ✓ | Spatial: ✓\n",
      "Overall: ✓ CORRECT\n",
      "Spatial GT: 'the center-center region' | Pred: 'the center-center region'\n",
      "Bbox: [139, 125, 536, 293]\n",
      "Area Coverage: 17.9%\n",
      "\n",
      "--- Test 38/50 ---\n",
      "Image: HF_sample_38\n",
      "Ground Truth: This appears to be melanocytic nevus. The lesion is located in the center-center region.\n",
      "Model Output: This appears to be melanocytic nevus. The lesion is located in the center-center region.\n",
      "Diagnosis: ✓ | Spatial: ✓\n",
      "Overall: ✓ CORRECT\n",
      "Spatial GT: 'the center-center region' | Pred: 'the center-center region'\n",
      "Bbox: [132, 137, 346, 336]\n",
      "Area Coverage: 11.6%\n",
      "\n",
      "--- Test 39/50 ---\n",
      "Image: HF_sample_39\n",
      "Ground Truth: This appears to be melanoma.\n",
      "Model Output: This appears to be melanocytic nevus.\n",
      "Diagnosis: ❌ | Spatial: ✓\n",
      "Overall: ❌ INCORRECT\n",
      "\n",
      "--- Test 40/50 ---\n",
      "Image: HF_sample_40\n",
      "Ground Truth: This appears to be melanocytic nevus. The lesion is located in the center-center region.\n",
      "Model Output: This appears to be melanocytic nevus. The lesion is located in the center-center region.\n",
      "Diagnosis: ✓ | Spatial: ✓\n",
      "Overall: ✓ CORRECT\n",
      "Spatial GT: 'the center-center region' | Pred: 'the center-center region'\n",
      "Bbox: [114, 59, 517, 380]\n",
      "Area Coverage: 30.9%\n",
      "\n",
      "--- Test 41/50 ---\n",
      "Image: HF_sample_41\n",
      "Ground Truth: This appears to be melanocytic nevus.\n",
      "Model Output: This appears to be melanocytic nevus.\n",
      "Diagnosis: ✓ | Spatial: ✓\n",
      "Overall: ✓ CORRECT\n",
      "\n",
      "--- Test 42/50 ---\n",
      "Image: HF_sample_42\n",
      "Ground Truth: This appears to be benign keratosis-like lesion.\n",
      "Model Output: This appears to be basal cell carcinoma.\n",
      "Diagnosis: ❌ | Spatial: ✓\n",
      "Overall: ❌ INCORRECT\n",
      "\n",
      "--- Test 43/50 ---\n",
      "Image: HF_sample_43\n",
      "Ground Truth: This appears to be melanocytic nevus.\n",
      "Model Output: This appears to be melanocytic nevus.\n",
      "Diagnosis: ✓ | Spatial: ✓\n",
      "Overall: ✓ CORRECT\n",
      "\n",
      "--- Test 44/50 ---\n",
      "Image: HF_sample_44\n",
      "Ground Truth: This appears to be actinic keratosis.\n",
      "Model Output: This appears to be basal cell carcinoma.\n",
      "Diagnosis: ❌ | Spatial: ✓\n",
      "Overall: ❌ INCORRECT\n",
      "\n",
      "--- Test 45/50 ---\n",
      "Image: HF_sample_45\n",
      "Ground Truth: This appears to be melanocytic nevus.\n",
      "Model Output: This appears to be melanocytic nevus.\n",
      "Diagnosis: ✓ | Spatial: ✓\n",
      "Overall: ✓ CORRECT\n",
      "\n",
      "--- Test 46/50 ---\n",
      "Image: HF_sample_46\n",
      "Ground Truth: This appears to be melanoma. The lesion is located in the center-center region.\n",
      "Model Output: This appears to be melanoma. The lesion is located in the center-center region.\n",
      "Diagnosis: ✓ | Spatial: ✓\n",
      "Overall: ✓ CORRECT\n",
      "Spatial GT: 'the center-center region' | Pred: 'the center-center region'\n",
      "Bbox: [141, 28, 495, 410]\n",
      "Area Coverage: 38.1%\n",
      "\n",
      "--- Test 47/50 ---\n",
      "Image: HF_sample_47\n",
      "Ground Truth: This appears to be melanocytic nevus.\n",
      "Model Output: This appears to be melanocytic nevus.\n",
      "Diagnosis: ✓ | Spatial: ✓\n",
      "Overall: ✓ CORRECT\n",
      "\n",
      "--- Test 48/50 ---\n",
      "Image: HF_sample_48\n",
      "Ground Truth: This appears to be melanocytic nevus.\n",
      "Model Output: This appears to be melanocytic nevus.\n",
      "Diagnosis: ✓ | Spatial: ✓\n",
      "Overall: ✓ CORRECT\n",
      "\n",
      "--- Test 49/50 ---\n",
      "Image: HF_sample_49\n",
      "Ground Truth: This appears to be melanocytic nevus.\n",
      "Model Output: This appears to be melanocytic nevus.\n",
      "Diagnosis: ✓ | Spatial: ✓\n",
      "Overall: ✓ CORRECT\n",
      "\n",
      "--- Test 50/50 ---\n",
      "Image: HF_sample_50\n",
      "Ground Truth: This appears to be melanocytic nevus.\n",
      "Model Output: This appears to be melanocytic nevus.\n",
      "Diagnosis: ✓ | Spatial: ✓\n",
      "Overall: ✓ CORRECT\n",
      "\n",
      "==================================================\n",
      "TEST SUMMARY:\n",
      "Overall Accuracy:    42/50 (84.0%)\n",
      "Diagnosis Accuracy:  42/50 (84.0%)\n",
      "Spatial Accuracy:    11/11 (100.0%) [11 spatial samples]\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "def test_hf_model(model, processor, test_samples, num_tests=50):\n",
    "    \"\"\"Test model on HF dataset samples\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    test_results = []\n",
    "    spatial_tests = []\n",
    "    \n",
    "    for i, sample in enumerate(test_samples[:num_tests]):\n",
    "        print(f\"\\n--- Test {i+1}/{num_tests} ---\")\n",
    "        \n",
    "        try:\n",
    "            # Load image on-demand from HF dataset\n",
    "            hf_index = sample[\"hf_index\"]\n",
    "            test_image = test_hf_data[hf_index]['image'].convert('RGB')\n",
    "            print(f\"Image: HF_sample_{i+1}\")\n",
    "            \n",
    "            # Create test prompt\n",
    "            has_spatial_data = sample[\"metadata\"][\"has_spatial\"]\n",
    "            if has_spatial_data:\n",
    "                user_prompt = \"Analyze this skin lesion, provide a diagnosis, and describe its location.\"\n",
    "            else:\n",
    "                user_prompt = \"Analyze this skin lesion and provide a diagnosis.\"\n",
    "            \n",
    "            conversation = [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"image\"},\n",
    "                        {\"type\": \"text\", \"text\": user_prompt}\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "            \n",
    "            # Generate response\n",
    "            text_prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "            inputs = processor(\n",
    "                text=[text_prompt], \n",
    "                images=[test_image], \n",
    "                return_tensors=\"pt\"\n",
    "            ).to(model.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                generated_ids = model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=256,\n",
    "                    do_sample=False\n",
    "                )\n",
    "            \n",
    "            response = processor.batch_decode(\n",
    "                generated_ids[:, inputs['input_ids'].shape[1]:], \n",
    "                skip_special_tokens=True\n",
    "            )[0].strip()\n",
    "            \n",
    "            # Get ground truth\n",
    "            ground_truth = sample[\"conversation\"][1][\"content\"][0][\"text\"]\n",
    "            \n",
    "            # Evaluate\n",
    "            diagnosis_keywords = {\n",
    "                'actinic keratosis': 'akiec',\n",
    "                'basal cell carcinoma': 'bcc', \n",
    "                'benign keratosis-like lesion': 'bkl',\n",
    "                'dermatofibroma': 'df',\n",
    "                'melanoma': 'mel',\n",
    "                'melanocytic nevus': 'nv',\n",
    "                'vascular lesion': 'vasc'\n",
    "            }\n",
    "            \n",
    "            # Check diagnosis\n",
    "            diagnosis_correct = False\n",
    "            for full_name, short_name in diagnosis_keywords.items():\n",
    "                if full_name in ground_truth.lower() and full_name in response.lower():\n",
    "                    diagnosis_correct = True\n",
    "                    break\n",
    "            \n",
    "            # Check spatial if applicable\n",
    "            spatial_correct = True\n",
    "            gt_spatial = \"\"\n",
    "            pred_spatial = \"\"\n",
    "            \n",
    "            if has_spatial_data:\n",
    "                if \"located in\" in ground_truth.lower():\n",
    "                    gt_spatial = ground_truth.split(\"located in\")[-1].strip().rstrip(\".\")\n",
    "                if \"located in\" in response.lower():\n",
    "                    pred_spatial = response.split(\"located in\")[-1].strip().rstrip(\".\")\n",
    "                \n",
    "                if gt_spatial and pred_spatial:\n",
    "                    spatial_correct = gt_spatial.lower() == pred_spatial.lower()\n",
    "                elif gt_spatial and not pred_spatial:\n",
    "                    spatial_correct = False\n",
    "                elif not gt_spatial and pred_spatial:\n",
    "                    spatial_correct = False\n",
    "            \n",
    "            is_correct = diagnosis_correct and spatial_correct\n",
    "            \n",
    "            print(f\"Ground Truth: {ground_truth}\")\n",
    "            print(f\"Model Output: {response}\")\n",
    "            print(f\"Diagnosis: {'✓' if diagnosis_correct else '❌'} | Spatial: {'✓' if spatial_correct else '❌' if has_spatial_data else 'N/A'}\")\n",
    "            print(f\"Overall: {'✓ CORRECT' if is_correct else '❌ INCORRECT'}\")\n",
    "            \n",
    "            if has_spatial_data and (gt_spatial or pred_spatial):\n",
    "                print(f\"Spatial GT: '{gt_spatial}' | Pred: '{pred_spatial}'\")\n",
    "                bbox_gt = sample[\"metadata\"].get(\"bbox\")\n",
    "                if bbox_gt and len(bbox_gt) == 4:\n",
    "                    print(f\"Bbox: [{bbox_gt[0]:.0f}, {bbox_gt[1]:.0f}, {bbox_gt[2]:.0f}, {bbox_gt[3]:.0f}]\")\n",
    "                    area_cov = sample[\"metadata\"].get(\"area_coverage\")\n",
    "                    if area_cov:\n",
    "                        print(f\"Area Coverage: {area_cov:.1%}\")\n",
    "            \n",
    "            # Store results\n",
    "            result = {\n",
    "                \"sample_id\": i,\n",
    "                \"diagnosis_correct\": diagnosis_correct,\n",
    "                \"spatial_correct\": spatial_correct,\n",
    "                \"overall_correct\": is_correct,\n",
    "                \"has_spatial\": has_spatial_data,\n",
    "                \"ground_truth\": ground_truth,\n",
    "                \"prediction\": response\n",
    "            }\n",
    "            test_results.append(result)\n",
    "            \n",
    "            if has_spatial_data:\n",
    "                spatial_tests.append(result)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error in test {i+1}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Summary\n",
    "    total_tests = len(test_results)\n",
    "    successful_tests = sum(1 for r in test_results if r[\"overall_correct\"])\n",
    "    diagnosis_correct = sum(1 for r in test_results if r[\"diagnosis_correct\"])\n",
    "    spatial_correct = sum(1 for r in spatial_tests if r[\"spatial_correct\"])\n",
    "    \n",
    "    overall_accuracy = (successful_tests / total_tests * 100) if total_tests > 0 else 0\n",
    "    diagnosis_accuracy = (diagnosis_correct / total_tests * 100) if total_tests > 0 else 0\n",
    "    spatial_accuracy = (spatial_correct / len(spatial_tests) * 100) if len(spatial_tests) > 0 else 0\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*50)\n",
    "    print(f\"TEST SUMMARY:\")\n",
    "    print(f\"Overall Accuracy:    {successful_tests}/{total_tests} ({overall_accuracy:.1f}%)\")\n",
    "    print(f\"Diagnosis Accuracy:  {diagnosis_correct}/{total_tests} ({diagnosis_accuracy:.1f}%)\")\n",
    "    print(f\"Spatial Accuracy:    {spatial_correct}/{len(spatial_tests)} ({spatial_accuracy:.1f}%) [{len(spatial_tests)} spatial samples]\")\n",
    "    print(f\"=\"*50)\n",
    "\n",
    "# Load the trained model and test\n",
    "loaded_model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    CONFIG[\"output_dir\"],\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "loaded_processor = Qwen2VLProcessor.from_pretrained(CONFIG[\"output_dir\"])\n",
    "\n",
    "print(\"Testing model...\")\n",
    "test_hf_model(loaded_model, loaded_processor, test_conversations, num_tests=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
